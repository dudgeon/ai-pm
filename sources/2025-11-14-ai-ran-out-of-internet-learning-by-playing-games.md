---
title: "AI Ran Out of Internet. Now It's Learning by Playing Games Again."
created: 2026-02-17
updated: 2026-02-17
template: templates/source.md
template_version: 3
tags: [source, ai-pm, claude-added]
status: unread
source_type: article
source_url: "https://every.to/playtesting/ai-ran-out-of-internet-now-it-s-learning-by-playing-games-again"
archive_url: ""
author: "Alex Duffy"
published: 2025-11-14
discovered: 2026-02-17
summary: "Alex Duffy argues that internet-trained AI models have exhausted public data and exhibit a 'jagged frontier' of uneven capabilities; games solve this by providing synthetic training environments with clear success metrics. Evidence: DeepSeek R1 improved via code/math self-play, Claude Sonnet 4.5 via Pokémon gameplay training. Games are ideal because scenarios are controllable, outcomes are scoreable, and the data is proprietary and dynamic — unlike static web text. Professional Go players improved after competing against AlphaGo, suggesting AI-human collaboration strengthens both."
domain: professional-development
project: ai-pm
---

## Raw Content

# AI Ran Out of Internet. Now It's Learning by Playing Games Again

## Main Argument

AI models trained on internet data face a critical limitation: they've exhausted publicly available training material. Games offer a solution by creating controlled environments where AI can learn through iterative play and evaluation.

## Key Problem: The "Jagged Frontier"

Current AI exhibits uneven capabilities. While some models excel at medical diagnosis and mathematical olympiad problems, they fail catastrophically in others—legal AI systems have "fabricated hundreds of facts and even whole cases that don't exist." This inconsistency stems from training data scarcity in specialized domains.

## Solution: Game-Based Learning

Games function as synthetic training environments where AI can practice, fail, and improve. The article notes: "In a game, we can create any scenario—a negotiation, a crisis, a moral dilemma, a portfolio to manage—and watch exactly how the AI responds."

## Evidence of Success

- DeepSeek's R1 model improved reasoning by playing code and math challenges against itself
- Claude Sonnet 4.5 advanced through Pokémon gameplay training
- Professional Go players improved dramatically after competing against AlphaGo, suggesting AI-human collaboration strengthens both

## Practical Applications

Good Start Labs partnered with Bad Cards, a humor-based game, to measure AI comedy preferences. Currently, leading models only predict human-chosen jokes 47% of the time, demonstrating substantial room for improvement through game-based training.
