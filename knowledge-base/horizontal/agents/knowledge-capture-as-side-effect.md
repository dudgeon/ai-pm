---
created: 2026-02-14
updated: 2026-02-14
template: templates/knowledge-entry.md
template_version: 4
tags: [knowledge, ai-pm, practice, agents, memory, knowledge-management]
status: draft
entry_type: practice
origin: sourced
featured: false
domain: horizontal
horizontal_domain: agents
project: ai-pm
---

# Knowledge Capture as Side Effect

## Summary

Design agent systems so that knowledge capture is a byproduct of corrections people are already making — not a separate documentation task. When a user corrects an agent ("don't call fetch directly, use the wrapper in src/lib/api-client"), the agent suggests persisting that correction as a knowledge item. The user reviews it, optionally edits, and saves. From that point on, every future session retrieves that knowledge when relevant.

This works because it eliminates the core failure mode of documentation: the cost of writing docs always loses to the cost of shipping features. Nobody maintains wikis because maintenance is a separate activity with deferred payoff. By embedding capture into the correction loop — something people do naturally when working with agents — the knowledge base grows as a side effect of normal work.

The pattern extends beyond chat corrections. Knowledge can also be auto-generated by scanning existing artifacts (READMEs, AGENTS.md, CLAUDE.md, .cursorrules, .rules files), and the system can suggest updates to existing items as conventions evolve. The combination of organic capture (corrections) and systematic extraction (repo scanning) covers both tacit and codified knowledge.

## How to Apply

**When to use**: When designing any agent system where users will repeatedly correct the same behaviors, establish conventions, or share tribal knowledge. This pattern is most valuable in team environments where knowledge must propagate across multiple users and sessions.

**When not to use**: For one-off corrections that aren't worth persisting, or in contexts where the overhead of review-and-save disrupts flow. The key is that the suggestion must be lightweight — a single confirmation, not a documentation workflow.

**Design principles**:
1. **Capture at the moment of correction**: The user is already articulating the knowledge when they correct the agent. Don't require them to context-switch into "documentation mode" — capture the correction in place.
2. **Human review before persistence**: The agent suggests; the human approves and refines. This ensures quality without requiring the human to initiate.
3. **Scope knowledge appropriately**: Not all knowledge is universal. Support scoping — repo-level conventions vs org-wide standards — to prevent context pollution. Backend deployment quirks shouldn't surface when working on the marketing site.
4. **Suggest updates, not just new items**: Conventions evolve. The system should detect when existing knowledge items may be stale and propose updates, not just accumulate new entries.
5. **Multiple input channels**: Chat corrections are the most organic source, but also extract from existing structured files (READMEs, rule files) and support manual creation for upfront codification.

**For AI PMs**: This pattern reframes the "how do we keep agent context current?" problem. Instead of building elaborate update workflows, design the agent's correction loop to double as a knowledge pipeline. The question shifts from "how do we document our conventions?" to "how do we make it trivial to persist corrections?"

## Sources

### From: [2026-02-13 Agentic Team Memory Devin](../../sources/2026-02-13-agentic-team-memory-devin.md)
**Key quote**: "You don't have to think about documentation while you're working, you just correct the agent the way you'd correct a teammate, and the system prompts you to persist what's worth keeping."
**Attribution**: Nader Dabit (@dabit3), Cognition
**What this source adds**: Demonstrates the pattern at scale in Devin's multi-user engineering environment. The multi-source approach (chat + repo scanning + suggested updates + manual) is the most comprehensive implementation documented. Scoped knowledge (repo-level vs org-wide) is a practical design detail.
**Links**: [Original](https://x.com/dabit3/status/2022459842342916559) | [Archive](../../sources/2026-02-13-agentic-team-memory-devin.md)

## Related

- [Filesystem as Agent State](filesystem-as-agent-state.md) — the captured knowledge needs to live somewhere; the filesystem-as-state model provides the storage substrate
- [Deliberate Context Selection](../context/deliberate-context-selection.md) — captured knowledge is only useful if it surfaces at the right time; scoped knowledge application is a form of deliberate selection
- [Reverse Engineer Judgment Into AI](../../ai-adoption/reverse-engineer-judgment-into-ai.md) — corrections encode expert judgment; this pattern is a mechanism for systematically extracting that judgment
