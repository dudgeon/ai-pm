---
created: 2026-02-13
updated: 2026-02-13
tags: [index, ai-pm-craft, horizontal, agent-lifecycle]
status: active
domain: professional-development
project: ai-pm-craft
---

# Horizontal: Agent Lifecycle

How PMs select, onboard, train, give feedback to, and performance-manage AI agents. This parallels human talent management but with fundamentally different mechanics — agents are configured, not convinced; their "skills" are shaped by context, prompts, and tool access rather than training programs.

## Scope

- Agent selection and evaluation — choosing the right agent/model for a task
- "Hiring" and onboarding — configuring agents for a role (system prompts, tool access, context loading)
- Training and skill development — improving agent performance through prompt engineering, fine-tuning, few-shot examples
- Ongoing feedback — correction loops, output review, quality standards
- Performance management — measuring agent effectiveness, knowing when to replace or reconfigure
- Agent portfolio management — managing multiple agents across different roles and workflows

## What Belongs Here

An entry belongs in Agent Lifecycle when it's:
- About managing agents as ongoing participants in work (not one-off prompting)
- Applicable across lifecycle phases (agent management happens in Discovery, Build, Release, etc.)
- Focused on the PM's relationship with agents as "team members" rather than tools

Individual prompting techniques that happen to be used during agent management may be better in [Practices](../practices/). The test: is this about *how to manage an agent over time* or *how to write a good prompt*?

## Relationship to the Product Lifecycle

Agent lifecycle management cuts across every phase. A PM might:
- **Discover**: Use research agents to synthesize market signals
- **Frame**: Use analysis agents to model business cases
- **Shape**: Use design agents to generate prototypes
- **Build**: Use coding agents to implement, review agents to QA
- **Release**: Use communication agents for release notes, monitoring agents for anomalies
- **Measure**: Use analytics agents for pattern detection

The *how* of managing those agents — selection criteria, onboarding patterns, feedback loops, performance measurement — is what lives here.

## Emerging Topics

- Agent-as-team-member mental models
- Agent onboarding patterns (system prompts, CLAUDE.md files, context loading)
- Feedback and correction loops (when and how to intervene)
- Agent performance measurement and replacement criteria
- Multi-agent coordination and handoff patterns
- The PM as "agent manager" role evolution

## Entries

*No entries yet.*

---

[← Back to Knowledge Map](../README.md)
